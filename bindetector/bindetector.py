"""
Mask R-CNN

------------------------------------------------------------

    # Train a new model starting from ImageNet weights
    python3 bindetector.py train --dataset=/path/to/dataset --subset=train --weights=coco

    # Resume training a model that you had trained earlier
    python3 bindetector.py train --dataset=/path/to/dataset --subset=train --weights=last

    Added:

     python bindetector.py train --dataset=bin_splits/ --weights=coco

    python bindetector.py detect --dataset=/dataset_main_folder --subset=test (must be called test) --weights=any
    python3 bindetector.py singledetect --image=.... --weights=last

    python3 bindetector.py splash, crap

    If stuck on memory
    sudo fuser -v /dev/nvidia* and kill PIDS
"""

# Set matplotlib backend
# This has to be done before other importa that might
# set it, but only if we're running in script mode
# rather than being imported.
if __name__ == '__main__':
    import matplotlib
    # Agg backend runs without a display
    matplotlib.use('Agg')
    import matplotlib.pyplot as plt

import os
import sys
import json
import datetime
import numpy as np
import skimage.io
import wandb
import keras
import scipy
from skimage.transform import resize
from wandb.keras import WandbCallback

from imgaug import augmenters as iaa

# Root directory of the project
ROOT_DIR = os.path.abspath("../")

# Import Mask RCNN
sys.path.append(ROOT_DIR)  # To find local version of the library
from mrcnn.config import Config
from mrcnn import utils
from mrcnn import model as modellib
from mrcnn import visualize
from mrcnn.model import load_image_gt
# Path to trained weights file
COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, "mask_rcnn_coco.h5")

# Directory to save logs and model checkpoints, if not provided
# through the command line argument --logs
DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, "logs")
CLASS_NAME="Bin" #or graybox
# Results directory
# Save submission files here
RESULTS_DIR = os.path.join(ROOT_DIR, "results/bindetector_res50/")

VAL_IMAGE_IDS = [
    "5c9404cb-6e81-4e24-8553-24deecc3c793_inst_0_class_Bin_seg_0_orig",
]

############################################################
#  Configurations
############################################################

class BinSegmentationConfig(Config):
    """Configuration for training on the BinSegmentation segmentation dataset."""
    # Give the configuration a recognizable name
    NAME = "Bins_res50"#CLASS_NAME#"graybox"
    GPU_COUNT = 1
    # Adjust depending on your GPU memory
    IMAGES_PER_GPU = 1

    # Number of classes (including background)
    NUM_CLASSES = 1 + 1  # Background + BinSegmentation

    # Number of training and validation steps per epoch
    STEPS_PER_EPOCH = 1000#(2293)//IMAGES_PER_GPU   #1621
    #STEPS_PER_EPOCH = (657 - len(VAL_IMAGE_IDS)) // IMAGES_PER_GPU
    VALIDATION_STEPS = 100#max(1, 962 // IMAGES_PER_GPU) #367

    # Don't exclude based on confidence. Since we have two classes
    # then 0.5 is the minimum anyway as it picks between BinSegmentation and BG
    DETECTION_MIN_CONFIDENCE = 0.7

    # Backbone network architecture
    # Supported values are: resnet50, resnet101
    BACKBONE = "resnet50"
    #TODO: Try  OPTIMIZER = "ADAM", already added to MODEL L:2394
    # Input image resizing
    # Random crops of size 512x512
    #IMAGE_RESIZE_MODE = "square"
    #IMAGE_RESIZE_MODE = "crop"
    #IMAGE_MIN_DIM = 512
    #IMAGE_MAX_DIM = 1024 #512
    #IMAGE_MIN_SCALE = 2.0
    IMAGE_MIN_DIM = 512
    IMAGE_MAX_DIM = 512
    # Length of square anchor side in pixels
    #RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)
    RPN_ANCHOR_SCALES = (32, 64, 128, 256, 512)
    # ROIs kept after non-maximum supression (training and inference)
    POST_NMS_ROIS_TRAINING = 1000
    POST_NMS_ROIS_INFERENCE = 2000

    # Non-max suppression threshold to filter RPN proposals.
    # You can increase this during training to generate more propsals.
    RPN_NMS_THRESHOLD = 0.9

    # How many anchors per image to use for RPN training
    #RPN_TRAIN_ANCHORS_PER_IMAGE = 64
    RPN_TRAIN_ANCHORS_PER_IMAGE = 256

    # Image mean (RGB)
    MEAN_PIXEL = np.array([99.22, 98.74, 97.40])

    # If enabled, resizes instance masks to a smaller size to reduce
    # memory load. Recommended when using high-resolution images.
    USE_MINI_MASK = True
    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask

    # Number of ROIs per image to feed to classifier/mask heads
    # The Mask RCNN paper uses 512 but often the RPN doesn't generate
    # enough positive proposals to fill this and keep a positive:negative
    # ratio of 1:3. You can increase the number of proposals by adjusting
    # the RPN NMS threshold.
    TRAIN_ROIS_PER_IMAGE = 128

    # Maximum number of ground truth instances to use in one image
    MAX_GT_INSTANCES = 100
    DEVICE = "/gpu:1"
    # Max number of final detections per image
    DETECTION_MAX_INSTANCES = 100

    # MODEL TUNING
    if os.environ.get('BACKBONE'):
        BACKBONE = os.environ.get('BACKBONE')
    if os.environ.get('GRADIENT_CLIP_NORM'):
        GRADIENT_CLIP_NORM = float(os.environ.get('GRADIENT_CLIP_NORM'))
    if os.environ.get('LEARNING_RATE'):
        LEARNING_RATE = float(os.environ.get('LEARNING_RATE'))
    if os.environ.get('WEIGHT_DECAY'):
        WEIGHT_DECAY = float(os.environ.get('WEIGHT_DECAY'))

    def get_config_dict(self):
        """Return Configuration values as a dictionary for the sake of syncing with wandb"""
        d = {}
        for a in dir(self):
            if not a.startswith("__") and not callable(getattr(self, a)):
                d[a] = getattr(self, a)
        return d


class BinSegmentationInferenceConfig(BinSegmentationConfig):
    # Set batch size to 1 to run one image at a time
    GPU_COUNT = 1
    IMAGES_PER_GPU = 1
    # Don't resize imager for inferencing
    IMAGE_RESIZE_MODE = "pad64"
    # Non-max suppression threshold to filter RPN proposals.
    # You can increase this during training to generate more propsals.
    RPN_NMS_THRESHOLD = 0.7


############################################################
#  Dataset
############################################################

class BinSegmentationDataset(utils.Dataset):

    def load_BinSegmentation(self, dataset_dir, subset):
        """Load a subset of the nuclei dataset.

        dataset_dir: Root directory of the dataset
        subset: Subset to load. Either the name of the sub-directory,
        """
        # Add classes. We have one class.
        # Naming the dataset BinSegmentation, and the class BinSegmentation
        self.add_class(CLASS_NAME, 1, CLASS_NAME)

        # Which subset
        # class_files = list(map(
        #     (lambda x: os.path.basename(x)),
        #     glob.glob('{}/*_class_{}*'.format(args.input_dir, "graybox"))))
        #if subset=="trainval":
        #    assert subset in ["train", "val"]
        #    dataset_dir = os.path.join(dataset_dir, subset)
        #else:
        if subset!='test':
            assert subset in ["train", "val"]
        dataset_dir = os.path.join(dataset_dir, subset)
        image_ids = next(os.walk(dataset_dir))[1]
        if subset=="val":
            print("VALIDATUIN size !!!!!!!!!!!!!!!!!!!!!!!: ")
            print(len(image_ids))
        if subset == "train":
            print("train  LENGTH!!!!!!!!!!!!!!!!!: ")
            print(len(image_ids))

        # Add images
        for image_id in image_ids:
            self.add_image(
                CLASS_NAME,
                image_id=image_id,
                path=os.path.join(dataset_dir, image_id, "images/{}.png".format(image_id)))

    def load_mask(self, image_id):
        """Generate instance masks for an image.
       Returns:
        masks: A bool array of shape [height, width, instance count] with
            one mask per instance.
        class_ids: a 1D array of class IDs of the instance masks.
        """
        info = self.image_info[image_id]

        # Get mask directory from image path
        mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), "masks")

        # Read mask files from .png image
        mask = []
        for f in next(os.walk(mask_dir))[2]:
            if f.endswith(".png"):
                m = skimage.io.imread(os.path.join(mask_dir, f)).astype(np.bool)
                mask.append(m)
        mask = np.stack(mask, axis=-1)
        # Return mask, and array of class IDs of each instance. Since we have
        # one class ID, we return an array of ones
        return mask, np.ones([mask.shape[-1]], dtype=np.int32)

    def image_reference(self, image_id):
        """Return the path of the image."""
        info = self.image_info[image_id]
        if info["source"] == CLASS_NAME:
            return info["id"]
        else:
            super(self.__class__, self).image_reference(image_id)


#WANDB --------------------------
#run = wandb.init()


#wandb.config.update(args)


def fig_to_array(fig):
    fig.canvas.draw()
    w, h = fig.canvas.get_width_height()
    buf = np.fromstring(fig.canvas.tostring_argb(), dtype=np.uint8)
    buf.shape = (w, h, 4)
    buf = np.roll(buf, 3, axis=2)
    return buf

class ImageCallback(keras.callbacks.Callback):
    def __init__(self, run, dataset_val, dataset_train):
        self.run = run
        self.dataset_val = dataset_val
        self.dataset_train = dataset_train
        self.image_ids = dataset_val.image_ids[4:10]

    def label_image(self, image_id):
        #plt.cla
        original_image, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(
            self.dataset_val, config, image_id, use_mini_mask=False)
        _, ax = plt.subplots(figsize=(16, 16))
        visualize.display_instances(
            original_image,
            gt_bbox,
            gt_mask,
            gt_class_id,
            self.dataset_train.class_names,
            figsize=(
                16,
                16),
            ax=ax)
        return fig_to_array(ax.figure)

    def on_epoch_end(self, epoch, logs):
        print("Uploading images to wandb...")
        labeled_images = [self.label_image(i) for i in self.image_ids]
        self.run.history.row["img_segmentations"] = [
            wandb.Image(
                skimage.transform.resize(img, (256,256)),
                caption="Caption",
                mode='RGBA') for img in labeled_images]

class PerformanceCallback(keras.callbacks.Callback):
    def __init__(self, run):
        self.run = run
    def on_epoch_end(self, epoch, logs):
        print("Uploading metrics to wandb...")
        self.run.history.row.update(logs)
        self.run.history.add()

############################################################
#  Training
############################################################

def train(model, dataset_dir, subset):
    """Train the model."""
    #wandb.init(project="mrcnn")
    #wandb.config.update(args)
    # Training dataset.
    dataset_train = BinSegmentationDataset()
    dataset_train.load_BinSegmentation(dataset_dir, "train")
    dataset_train.prepare()

    # Validation dataset
    dataset_val = BinSegmentationDataset()
    dataset_val.load_BinSegmentation(dataset_dir, "val")
    dataset_val.prepare()

    # Image augmentation
    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html
    #augmentation = iaa.SomeOf((0, 2), [
    #    iaa.Fliplr(0.5),
    #    iaa.Flipud(0.5),
    #    iaa.OneOf([iaa.Affine(rotate=90),
    #               iaa.Affine(rotate=180),
    #               iaa.Affine(rotate=270)]),
    #    iaa.Multiply((0.8, 1.5)),
    #    iaa.GaussianBlur(sigma=(0.0, 5.0))
    #])

    # *** This training schedule is an example. Update to your needs ***

    # If starting from imagenet, train heads only for a bit
    # since they have random weights
    print("Train network heads")
    #physical_devices = tf.config.experimental.list_physical_devices('GPU')
    #if len(physical_devices) > 0:
    #    tf.config.experimental.set_memory_growth(physical_devices[0], True)
    #    tf.config.experimental.set_memory_growth(physical_devices[1], True)
    #config.GPU_COUNT=2
    callbacks = [
            ImageCallback(
                run,
                dataset_val,
                dataset_train),
            PerformanceCallback(run)
    ]
    model.train(dataset_train, dataset_val,
                learning_rate=config.LEARNING_RATE,
                epochs=20,#20
                #augmentation=augmentation,
                layers='heads')

    print("Train all layers")
    model.train(dataset_train, dataset_val,
                learning_rate=config.LEARNING_RATE,
                epochs=40,#40
                #augmentation=augmentation,
                layers='4+')
    #print("Fine tune all layers")
    #model.train(dataset_train, dataset_val,
    #            learning_rate=config.LEARNING_RATE / 10,
    #            epochs=40,
    #            layers='all',
    #            )



############################################################
#  RLE Encoding
############################################################

def rle_encode(mask):
    """Encodes a mask in Run Length Encoding (RLE).
    Returns a string of space-separated values.
    """
    assert mask.ndim == 2, "Mask must be of shape [Height, Width]"
    # Flatten it column wise
    m = mask.T.flatten()
    # Compute gradient. Equals 1 or -1 at transition points
    g = np.diff(np.concatenate([[0], m, [0]]), n=1)
    # 1-based indicies of transition points (where gradient != 0)
    rle = np.where(g != 0)[0].reshape([-1, 2]) + 1
    # Convert second index in each pair to lenth
    rle[:, 1] = rle[:, 1] - rle[:, 0]
    return " ".join(map(str, rle.flatten()))


def rle_decode(rle, shape):
    """Decodes an RLE encoded list of space separated
    numbers and returns a binary mask."""
    rle = list(map(int, rle.split()))
    rle = np.array(rle, dtype=np.int32).reshape([-1, 2])
    rle[:, 1] += rle[:, 0]
    rle -= 1
    mask = np.zeros([shape[0] * shape[1]], np.bool)
    for s, e in rle:
        assert 0 <= s < mask.shape[0]
        assert 1 <= e <= mask.shape[0], "shape: {}  s {}  e {}".format(shape, s, e)
        mask[s:e] = 1
    # Reshape and transpose
    mask = mask.reshape([shape[1], shape[0]]).T
    return mask


def mask_to_rle(image_id, mask, scores):
    "Encodes instance masks to submission format."
    assert mask.ndim == 3, "Mask must be [H, W, count]"
    # If mask is empty, return line with image ID only
    if mask.shape[-1] == 0:
        return "{},".format(image_id)
    # Remove mask overlaps
    # Multiply each instance mask by its score order
    # then take the maximum across the last dimension
    order = np.argsort(scores)[::-1] + 1  # 1-based descending
    mask = np.max(mask * np.reshape(order, [1, 1, -1]), -1)
    # Loop over instance masks
    lines = []
    for o in order:
        m = np.where(mask == o, 1, 0)
        # Skip if empty
        if m.sum() == 0.0:
            continue
        rle = rle_encode(m)
        lines.append("{}, {}".format(image_id, rle))
    return "\n".join(lines)


############################################################
#  Detection
############################################################

def detectsingleimg(model, image_path=None):
    """Run detection on images in the given directory."""
    #print("Running on {}".format(dataset_dir))
    assert image_path
    # Image or video?
    if image_path:
        # Run model detection and generate the color splash effect
        print("Running on {}".format(args.image))
        # Read image
        image = skimage.io.imread(args.image)
        # Detect objects
        r = model.detect([image], verbose=1)[0]
        print('Found ', len(r['masks']))
        print('Found ', len(r['rois']))
        for rio in r['rois']:
            print(rio)
        # Color splash
        visualize.display_instances(
            image, r['rois'], r['masks'], r['class_ids'],
            CLASS_NAME, r['scores'],
            show_bbox=True, show_mask=True,
            title="Predictions")
        file_name = "splashPredict_{:%Y%m%dT%H%M%S}".format(datetime.datetime.now())
        plt.savefig("{}.png".format(file_name,image))
        #skimage.io.imsave(file_name, splash)
    print("Saved to ", file_name)




def detect(model, dataset_dir, subset):
    """Run detection on images in the given directory."""
    print("Running on {}".format(dataset_dir))

    # Create directory
    if not os.path.exists(RESULTS_DIR):
        os.makedirs(RESULTS_DIR)
    submit_dir = "submit_{:%Y%m%dT%H%M%S}".format(datetime.datetime.now())
    submit_dir = os.path.join(RESULTS_DIR, submit_dir)
    os.makedirs(submit_dir)

    # Read dataset
    dataset = BinSegmentationDataset()
    dataset.load_BinSegmentation(dataset_dir, 'test')
    #dataset.load_BinSegmentation(dataset_dir, subset)
    dataset.prepare()
    # Load over images
    submission = []
    for image_id in dataset.image_ids:
        # Load image and run detection
        image = dataset.load_image(image_id)
        # Detect objects
        r = model.detect([image], verbose=0)[0]
        # Encode image to RLE. Returns a string of multiple lines
        source_id = dataset.image_info[image_id]["id"]
        rle = mask_to_rle(source_id, r["masks"], r["scores"])
        submission.append(rle)
        # Save image with masks
        visualize.display_instances(
            image, r['rois'], r['masks'], r['class_ids'],
            dataset.class_names, r['scores'],
            show_bbox=True, show_mask=True,
            title="Predictions")
        plt.savefig("{}/{}.png".format(submit_dir, dataset.image_info[image_id]["id"]))

    # Save to csv file
    submission = "ImageId,EncodedPixels\n" + "\n".join(submission)
    file_path = os.path.join(submit_dir, "submit.csv")
    with open(file_path, "w") as f:
        f.write(submission)
    print("Saved to ", submit_dir)

def detectsplash(model, dataset_dir, subset):
    """Run detection on images in the given directory."""
    print("Running on {}".format(dataset_dir))

    # Create directory
    if not os.path.exists(RESULTS_DIR):
        os.makedirs(RESULTS_DIR)
    submit_dir = "submit_{:%Y%m%dT%H%M%S}".format(datetime.datetime.now())
    submit_dir = os.path.join(RESULTS_DIR, submit_dir)
    os.makedirs(submit_dir)

    # Read dataset
    dataset = BinSegmentationDataset()
    dataset.load_BinSegmentation(dataset_dir, subset)
    dataset.prepare()
    # Load over images
    submission = []
    for image_id in dataset.image_ids:
        # Load image and run detection
        image = dataset.load_image(image_id)
        # Detect objects
        r = model.detect([image], verbose=0)[0]
        # Encode image to RLE. Returns a string of multiple lines
        source_id = dataset.image_info[image_id]["id"]
        rle = mask_to_rle(source_id, r["masks"], r["scores"])
        submission.append(rle)
        # Save image with masks
        # Color splash
        #splash = color_splash(image, r['masks'])
        # Save output
        #file_name = "splash_{:%Y%m%dT%H%M%S}.png".format(datetime.datetime.now())
        #skimage.io.imsave(file_name, splash)
        visualize.display_instances(
            image, r['rois'], r['masks'], r['class_ids'],
            dataset.class_names, r['scores'],
            show_bbox=False, show_mask=False,
            title="Predictions")
        plt.savefig("{}/{}.png".format(submit_dir, dataset.image_info[image_id]["id"]))

    # Save to csv file
    submission = "ImageId,EncodedPixels\n" + "\n".join(submission)
    file_path = os.path.join(submit_dir, "submit.csv")
    with open(file_path, "w") as f:
        f.write(submission)
    print("Saved to ", submit_dir)

def color_splash(image, mask):
    """Apply color splash effect.
    image: RGB image [height, width, 3]
    mask: instance segmentation mask [height, width, instance count]

    Returns result image.
    """
    # Make a grayscale copy of the image. The grayscale copy still
    # has 3 RGB channels, though.
    gray = skimage.color.gray2rgb(skimage.color.rgb2gray(image)) * 255
    # Copy color pixels from the original color image where mask is set
    if mask.shape[-1] > 0:
        # We're treating all instances as one, so collapse the mask into one layer
        mask = (np.sum(mask, -1, keepdims=True) >= 1)
        splash = np.where(mask, image, gray).astype(np.uint8)
    else:
        splash = gray.astype(np.uint8)
    return splash


def detect_and_color_splash(model, image_path=None):
    assert image_path
    # Image or video?
    if image_path:
        # Run model detection and generate the color splash effect
        print("Running on {}".format(args.image))
        # Read image
        image = skimage.io.imread(args.image)
        # Detect objects
        r = model.detect([image], verbose=1)[0]
        print('Found ', len(r['masks']))
        print('Found ', len(r['rois']))
        for rio in r['rois']:
            print(rio)
        # Color splash
        splash = color_splash(image, r['masks'])
        # Save output
        file_name = "splash_{:%Y%m%dT%H%M%S}.png".format(datetime.datetime.now())
        skimage.io.imsave(file_name, splash)
    print("Saved to ", file_name)




############################################################
#  Command Line
############################################################

if __name__ == '__main__':
    import argparse

    # Parse command line arguments
    parser = argparse.ArgumentParser(
        description='Mask R-CNN for box segmentation')
    parser.add_argument("command",
                        metavar="<command>",
                        help="'train' or 'singledetect' or 'detect' or 'splash'")
    parser.add_argument('--dataset', required=False,
                        metavar="/path/to/dataset/",
                        help='Root directory of the dataset')
    parser.add_argument('--weights', required=True,
                        metavar="/path/to/weights.h5",
                        help="Path to weights .h5 file or 'coco'")
    parser.add_argument('--logs', required=False,
                        default=DEFAULT_LOGS_DIR,
                        metavar="/path/to/logs/",
                        help='Logs and checkpoints directory (default=logs/)')
    parser.add_argument('--subset', required=False,
                        metavar="Dataset sub-directory",
                        help="Subset of dataset to run prediction on")
    parser.add_argument('--image', required=False,
                        metavar="path or URL to image",
                        help='Image to apply the color splash effect on')
    parser.add_argument('--classname', required=False,
                        default=CLASS_NAME,
                        metavar="Class names",
                        help='Class names, str')
    args = parser.parse_args()
    if args.weights.lower() == "last":
        run=wandb.init(project="mrcnn", resume=True)
    else:
        run = wandb.init(project="mrcnn")

    config = BinSegmentationConfig()
    wandb.config.update(args)
    config_dict = config.get_config_dict()
    configs_of_interest = ['BACKBONE', 'GRADIENT_CLIP_NORM', 'LEARNING_MOMENTUM', 'LEARNING_RATE',
                           'WEIGHT_DECAY', 'STEPS_PER_EPOCH']
    # wandb_callb=WandbCallback(save_model=True)
    run.history.row.update({k: config_dict[k] for k in configs_of_interest})


    print("CLASS NAME!:",args.classname)
    CLASS_NAME=args.classname


    # Validate arguments
    if args.command == "train":
        assert args.dataset, "Argument --dataset is required for training"
    elif args.command == "detect":
        assert args.subset, "Provide --subset to run prediction on"
    elif args.command == "splash":
        assert args.image
    elif args.command == "singledetect":
        assert args.image\


    print("Weights: ", args.weights)
    print("Dataset: ", args.dataset)
    if args.subset:
        print("Subset: ", args.subset)
    print("Logs: ", args.logs)

    # Configurations
    if args.command == "train":

        config = BinSegmentationConfig()

    else:
        config = BinSegmentationInferenceConfig()
    config.display()

    dataset_train = BinSegmentationDataset()
    dataset_train.load_BinSegmentation(args.dataset, "train")
    dataset_train.prepare()

    # Validation dataset
    dataset_val = BinSegmentationDataset()
    dataset_val.load_BinSegmentation(args.dataset, "val")
    dataset_val.prepare()
    callbacks = [
        ImageCallback(
            run,
            dataset_val,
            dataset_train),
        PerformanceCallback(run)
    ]

    # Create model
    if args.command == "train":
        model = modellib.MaskRCNN(mode="training", config=config,
                                  model_dir=args.logs, callbacks=callbacks)

    else:
        model = modellib.MaskRCNN(mode="inference", config=config,
                                  model_dir=args.logs, callbacks=None)


    # Select weights file to load
    if args.weights.lower() == "coco":
        weights_path = COCO_WEIGHTS_PATH
        # Download weights file
        if not os.path.exists(weights_path):
            utils.download_trained_weights(weights_path)
    elif args.weights.lower() == "last":
        # Find last trained weights
        weights_path = model.find_last()
    elif args.weights.lower() == "imagenet":
        # Start from ImageNet trained weights
        weights_path = model.get_imagenet_weights()
    else:
        weights_path = args.weights

    # Load weights
    print("Loading weights ", weights_path)
    if args.weights.lower() == "coco":
        # Exclude the last layers because they require a matching
        # number of classes
        model.load_weights(weights_path, by_name=True, exclude=[
            "mrcnn_class_logits", "mrcnn_bbox_fc",
            "mrcnn_bbox", "mrcnn_mask"])
    else:
        model.load_weights(weights_path, by_name=True)

    # Train or evaluate
    if args.command == "train":
        print("FIIIIX")
        #train(model, args.dataset, args.subset)
        model.train(dataset_train, dataset_val,
                    learning_rate=config.LEARNING_RATE,
                    epochs=20,  # 20
                    # augmentation=augmentation,
                    layers='heads')

        print("Train all layers")
        model.train(dataset_train, dataset_val,
                    learning_rate=config.LEARNING_RATE,
                    epochs=50,  # 40
                    # augmentation=augmentation,
                    layers='all')

    elif args.command == "detect":
        detect(model, args.dataset, args.subset)
    elif args.command == "splash":
        detect_and_color_splash(model, image_path=args.image)
    elif args.command == "singledetect":
        detectsingleimg(model, image_path=args.image)
    else:
        print("'{}' is not recognized. "
              "Use 'train' or 'detect'".format(args.command))
